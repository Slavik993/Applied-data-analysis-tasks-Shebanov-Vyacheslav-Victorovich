{"cells":[{"cell_type":"markdown","id":"06732829","metadata":{"id":"06732829"},"source":["\n","# Русский стемминг и лемматизация — примеры\n","\n","\n","- **Стемминг** (Snowball, NLTK)\n","- **Лемматизация**: **pymorphy2** и **pymystem3**\n","\n","> Если пакет не установлен, раскомментируйте `pip install` в соответствующей ячейке.\n"]},{"cell_type":"markdown","id":"59f5dcd6","metadata":{"id":"59f5dcd6"},"source":["## 1. Примерные слова и фразы"]},{"cell_type":"code","id":"17d15b28","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:06.512373Z","start_time":"2025-10-06T00:24:06.509496Z"},"id":"17d15b28","outputId":"a3084eb8-3096-4d95-8b0a-e7a1295955e5"},"source":["\n","WORDS = [\n","    \"машины\", \"машинке\", \"поездки\", \"поехать\", \"бегаю\", \"бегала\",\n","    \"хорошие\", \"лучший\", \"прочитанная\", \"прочитать\", \"синие\", \"синего\",\n","    \"детям\", \"детский\", \"идущего\", \"идти\", \"вкуснейший\", \"вкусный\"\n","]\n","\n","TEXTS = [\n","    \"Мне не понравились машины: слишком дорогие и неудобные.\",\n","    \"Книга прочитанная мной — лучшая за этот год.\",\n","    \"Детский лагерь оказался очень уютным и дружелюбным.\",\n","]\n","print(\"Пример слов:\", WORDS[:8])\n","print(\"Пример фраз:\", TEXTS[0])\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["Пример слов: ['машины', 'машинке', 'поездки', 'поехать', 'бегаю', 'бегала', 'хорошие', 'лучший']\n","Пример фраз: Мне не понравились машины: слишком дорогие и неудобные.\n"]}],"execution_count":null},{"cell_type":"markdown","id":"14782949","metadata":{"id":"14782949"},"source":["## 2. Стемминг (NLTK SnowballStemmer)"]},{"cell_type":"code","id":"ceddbe78","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:06.566511Z","start_time":"2025-10-06T00:24:06.563207Z"},"id":"ceddbe78","outputId":"b43b9817-7122-467b-fc05-80376b0990ec"},"source":["\n","from nltk.stem.snowball import SnowballStemmer\n","stemmer = SnowballStemmer(\"russian\")\n","stems = [stemmer.stem(w.lower()) for w in WORDS]\n","for w, s in zip(WORDS, stems):\n","    print(f\"{w:12s} -> {s}\")\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["машины       -> машин\n","машинке      -> машинк\n","поездки      -> поездк\n","поехать      -> поеха\n","бегаю        -> бега\n","бегала       -> бега\n","хорошие      -> хорош\n","лучший       -> лучш\n","прочитанная  -> прочита\n","прочитать    -> прочита\n","синие        -> син\n","синего       -> син\n","детям        -> дет\n","детский      -> детск\n","идущего      -> идущ\n","идти         -> идт\n","вкуснейший   -> вкусн\n","вкусный      -> вкусн\n"]}],"execution_count":null},{"cell_type":"markdown","id":"5d86e70d","metadata":{"id":"5d86e70d"},"source":["## 3. Лемматизация (pymorphy2)"]},{"metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:06.623509Z","start_time":"2025-10-06T00:24:06.619931Z"},"id":"4d792298887f2da6"},"cell_type":"code","source":["# !pip -q install pymorphy2"],"id":"4d792298887f2da6","outputs":[],"execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:06.719512Z","start_time":"2025-10-06T00:24:06.672849Z"},"id":"9e1742676a92f828"},"cell_type":"code","source":["import pymorphy2\n","morph = pymorphy2.MorphAnalyzer()"],"id":"9e1742676a92f828","outputs":[],"execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:06.729645Z","start_time":"2025-10-06T00:24:06.726407Z"},"id":"596d08abf347fa71","outputId":"87264e9e-6d43-4006-d290-5a1b8254bfe8"},"cell_type":"code","source":["print(morph.parse(\"детям\"))\n","print(morph.parse(\"детям\")[0])\n","print(morph.parse(\"детям\")[0].normal_form)\n","print(morph.parse(\"детям\")[0].tag.POS)\n","\n","#see https://pymorphy2.readthedocs.io/en/stable/user/guide.html"],"id":"596d08abf347fa71","outputs":[{"name":"stdout","output_type":"stream","text":["[Parse(word='детям', tag=OpencorporaTag('NOUN,anim,masc plur,datv'), normal_form='ребёнок', score=1.0, methods_stack=((DictionaryAnalyzer(), 'детям', 2780, 8),))]\n","Parse(word='детям', tag=OpencorporaTag('NOUN,anim,masc plur,datv'), normal_form='ребёнок', score=1.0, methods_stack=((DictionaryAnalyzer(), 'детям', 2780, 8),))\n","ребёнок\n","NOUN\n"]}],"execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:06.778934Z","start_time":"2025-10-06T00:24:06.775094Z"},"id":"5b94cef2","outputId":"08139d48-2e53-4fca-d00c-def5752ae732"},"cell_type":"code","source":["\n","lemmas_pymorphy = [morph.parse(w)[0].normal_form for w in WORDS]\n","print(\"pymorphy2 леммы:\")\n","for w, l in zip(WORDS, lemmas_pymorphy):\n","    print(f\"{w:12s} -> {l}\")\n","\n"],"id":"5b94cef2","outputs":[{"name":"stdout","output_type":"stream","text":["pymorphy2 леммы:\n","машины       -> машина\n","машинке      -> машинка\n","поездки      -> поездка\n","поехать      -> поехать\n","бегаю        -> бегать\n","бегала       -> бегать\n","хорошие      -> хороший\n","лучший       -> хороший\n","прочитанная  -> прочитать\n","прочитать    -> прочитать\n","синие        -> синий\n","синего       -> синий\n","детям        -> ребёнок\n","детский      -> детский\n","идущего      -> идти\n","идти         -> идти\n","вкуснейший   -> вкусный\n","вкусный      -> вкусный\n"]}],"execution_count":null},{"cell_type":"markdown","id":"b66640d4","metadata":{"id":"b66640d4"},"source":["## 4. Лемматизация (pymystem3 / Yandex Mystem)"]},{"cell_type":"code","id":"1681d7c3","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:07.265756Z","start_time":"2025-10-06T00:24:06.835148Z"},"id":"1681d7c3","outputId":"8d983498-6b45-4bd2-c6a0-cd8be6c102bc"},"source":["\n","# !pip -q install pymystem3\n","try:\n","    from pymystem3 import Mystem\n","    mystem = Mystem()\n","    lemmas_mystem_words = [mystem.lemmatize(w)[0] for w in WORDS]\n","    lemmas_mystem_texts = [\" \".join([t for t in mystem.lemmatize(s) if t.strip()]) for s in TEXTS]\n","\n","    print(\"pymystem3 леммы (слова):\")\n","    for w, l in zip(WORDS, lemmas_mystem_words):\n","        print(f\"{w:12s} -> {l.strip()}\")\n","\n","    print(\"\\nЛемматизация фраз (pymystem3):\")\n","    for s, l in zip(TEXTS, lemmas_mystem_texts):\n","        print(\"Исходное:\", s)\n","        print(\"Леммы:   \", l.strip())\n","        print(\"-\" * 40)\n","except Exception as e:\n","    print(\"pymystem3 недоступен. Установите пакет и повторите. Ошибка:\", e)\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["pymystem3 леммы (слова):\n","машины       -> машина\n","машинке      -> машинка\n","поездки      -> поездка\n","поехать      -> поехать\n","бегаю        -> бегать\n","бегала       -> бегать\n","хорошие      -> хороший\n","лучший       -> хороший\n","прочитанная  -> прочитывать\n","прочитать    -> прочитывать\n","синие        -> синий\n","синего       -> синий\n","детям        -> ребенок\n","детский      -> детский\n","идущего      -> идти\n","идти         -> идти\n","вкуснейший   -> вкусный\n","вкусный      -> вкусный\n","\n","Лемматизация фраз (pymystem3):\n","Исходное: Мне не понравились машины: слишком дорогие и неудобные.\n","Леммы:    я не понравиться машина :  слишком дорогой и неудобный .\n","----------------------------------------\n","Исходное: Книга прочитанная мной — лучшая за этот год.\n","Леммы:    книга прочитывать я  —  хороший за этот год .\n","----------------------------------------\n","Исходное: Детский лагерь оказался очень уютным и дружелюбным.\n","Леммы:    детский лагерь оказываться очень уютный и дружелюбный .\n","----------------------------------------\n"]}],"execution_count":null},{"cell_type":"markdown","id":"4ddb4c00","metadata":{"id":"4ddb4c00"},"source":["## 5. Обработка «не» + лемматизация"]},{"cell_type":"code","id":"3bdf391b","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:07.457732Z","start_time":"2025-10-06T00:24:07.273593Z"},"id":"3bdf391b","outputId":"4b9ff5ae-3802-46a8-df55-c1b23deeef20"},"source":["\n","import re\n","token_re = re.compile(r\"[А-Яа-яЁёA-Za-z]+\")\n","\n","def get_lem_fn():\n","    m = pymorphy2.MorphAnalyzer()\n","    return lambda tok: m.parse(tok)[0].normal_form\n","\n","\n","def lemmatize(text):\n","    m = pymorphy2.MorphAnalyzer()\n","    tokens = token_re.findall(text.lower())\n","    out = []\n","    for t in tokens:\n","        if t == \"не\":\n","            out.append(t)\n","        else:\n","            out.append( m.parse(t)[0].normal_form)\n","    return out\n","\n","for s in TEXTS:\n","    print(\"Текст: \", s)\n","    print(\"Леммы с 'не':\", lemmatize(s))\n","    print(\"-\"*40)\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["Текст:  Мне не понравились машины: слишком дорогие и неудобные.\n","Леммы с 'не': ['я', 'не', 'понравиться', 'машина', 'слишком', 'дорогой', 'и', 'неудобный']\n","----------------------------------------\n","Текст:  Книга прочитанная мной — лучшая за этот год.\n","Леммы с 'не': ['книга', 'прочитать', 'я', 'хороший', 'за', 'этот', 'год']\n","----------------------------------------\n","Текст:  Детский лагерь оказался очень уютным и дружелюбным.\n","Леммы с 'не': ['детский', 'лагерь', 'оказаться', 'очень', 'уютный', 'и', 'дружелюбный']\n","----------------------------------------\n"]}],"execution_count":null},{"cell_type":"markdown","id":"ae442cf0","metadata":{"id":"ae442cf0"},"source":["## 6. Сравнение: стемминг vs лемматизация"]},{"cell_type":"code","id":"257f6d5f","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:07.509746Z","start_time":"2025-10-06T00:24:07.465954Z"},"id":"257f6d5f","outputId":"2767cbf4-e737-455f-b09c-3f3e800c88f5"},"source":["\n","def compare_stem_lemma(words):\n","    from nltk.stem.snowball import SnowballStemmer\n","    st = SnowballStemmer(\"russian\")\n","    stems = [st.stem(w.lower()) for w in words]\n","\n","    lemma_fn = get_lem_fn()\n","    lemmas = [lemma_fn(w.lower()) for w in words]\n","\n","    print(f\"{'Слово':14s} | {'Стим':12s} | {'Лемма':12s}\")\n","    print(\"-\"*44)\n","    for w, s, l in zip(words, stems, lemmas):\n","        print(f\"{w:14s} | {s:12s} | {l:12s}\")\n","\n","compare_stem_lemma(WORDS[:12])\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["Слово          | Стим         | Лемма       \n","--------------------------------------------\n","машины         | машин        | машина      \n","машинке        | машинк       | машинка     \n","поездки        | поездк       | поездка     \n","поехать        | поеха        | поехать     \n","бегаю          | бега         | бегать      \n","бегала         | бега         | бегать      \n","хорошие        | хорош        | хороший     \n","лучший         | лучш         | хороший     \n","прочитанная    | прочита      | прочитать   \n","прочитать      | прочита      | прочитать   \n","синие          | син          | синий       \n","синего         | син          | синий       \n"]}],"execution_count":null},{"cell_type":"markdown","id":"96bc84d4","metadata":{"id":"96bc84d4"},"source":["## 7. Нормализация токенов"]},{"cell_type":"code","id":"d9610d46","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:07.564143Z","start_time":"2025-10-06T00:24:07.519110Z"},"id":"d9610d46","outputId":"ffcaad0f-b034-40d7-807b-74a378128995"},"source":["\n","def normalize_tokens(text, mode='lemma'):\n","    import re\n","    token_re = re.compile(r\"[А-Яа-яЁёA-Za-z]+\")\n","    toks = [t.lower() for t in token_re.findall(text)]\n","    if mode == 'raw':\n","        return toks\n","    elif mode == 'stem':\n","        from nltk.stem.snowball import SnowballStemmer\n","        st = SnowballStemmer(\"russian\")\n","        return [st.stem(t) for t in toks]\n","    else:\n","        lemma_fn = get_lem_fn()\n","        return [lemma_fn(t) for t in toks]\n","\n","sample = \"Потрясающие машины стояли вдоль дороги, а дети радостно бегали.\"\n","for mode in ['raw', 'stem', 'lemma']:\n","    print(mode, \"->\", normalize_tokens(sample, mode=mode))\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["raw -> ['потрясающие', 'машины', 'стояли', 'вдоль', 'дороги', 'а', 'дети', 'радостно', 'бегали']\n","stem -> ['потряса', 'машин', 'стоя', 'вдол', 'дорог', 'а', 'дет', 'радостн', 'бега']\n","lemma -> ['потрясать', 'машина', 'стоять', 'вдоль', 'дорога', 'а', 'ребёнок', 'радостно', 'бегать']\n"]}],"execution_count":null},{"cell_type":"markdown","id":"6435b68a","metadata":{"id":"6435b68a"},"source":["\n","## 8. Представления текста: Bag of Words (BoW) и TF-IDF\n","\n","Перед тем как применять модели машинного обучения, текст нужно преобразовать в **числовой формат**.  \n","Существуют два базовых способа — **BoW** и **TF-IDF**.\n","\n","---\n","\n","### 1. Bag of Words (мешок слов)\n","\n","**Идея:** представляем текст как набор слов без учёта их порядка.  \n","Для каждого слова из словаря (всех слов корпуса) считаем, сколько раз оно встречается в документе.\n","\n","Пример:\n","\n","| Документ | Текст |\n","|-----------|-------|\n","| D1 | \"кошки любят молоко\" |\n","| D2 | \"собаки тоже любят молоко\" |\n","\n","Словарь (все уникальные слова):  \n","`[\"кошки\", \"любят\", \"молоко\", \"собаки\", \"тоже\"]`\n","\n","Тогда векторы:\n","\n","| Слово      | D1 | D2 |\n","|-------------|----|----|\n","| кошки       | 1  | 0  |\n","| любят       | 1  | 1  |\n","| молоко      | 1  | 1  |\n","| собаки      | 0  | 1  |\n","| тоже        | 0  | 1  |\n","\n","BoW-вектор для D1 = `[1, 1, 1, 0, 0]`\n","\n","**Минус:** модель не различает порядок слов и значимость каждого слова — часто встречающиеся вроде «и», «в», «на» могут доминировать.\n","\n","---\n","\n","### 2. TF-IDF (Term Frequency — Inverse Document Frequency)\n","\n","TF-IDF учитывает **вес слова**, то есть его важность в контексте всего корпуса.\n","\n","**Формулы** для слова *t* в документе *d*:\n","\n","\\[\n","TF(t, d) = \\frac{\\text{кол-во вхождений t в d}}{\\text{общее число слов в d}}\n","\\]\n","\n","\\[\n","IDF(t) = \\log\\frac{N}{1 + n_t}\n","\\]\n","\n","где *N* — число документов, *nₜ* — в скольких документах встречается слово *t*.\n","\n","\\[\n","TFIDF(t, d) = TF(t, d) \\times IDF(t)\n","\\]\n","\n","Чем чаще слово встречается в конкретном документе, но реже — во всём корпусе, тем выше его вес.  \n","TF-IDF подавляет «общие» слова (вроде “и”, “на”) и усиливает уникальные (“молоко”, “кошки”).\n","\n","---\n","\n","### 3. Интуитивно\n","\n","| Слово | Частое везде | Редкое, но информативное |\n","|--------|---------------|--------------------------|\n","| и, но, на | низкий TF-IDF | — |\n","| кошка, молоко | — | высокий TF-IDF |\n","\n","---\n","\n","###  Вывод\n","\n","- **BoW** — простая частотная модель (учёт словаря, подсчёт частот).  \n","- **TF-IDF** — «умная» версия BoW, добавляющая взвешивание по важности.  \n","Используется почти во всех классических NLP-моделях (логистическая регрессия, наивный Байес, SVM и др.).\n"]},{"cell_type":"code","id":"5604135d","metadata":{"ExecuteTime":{"end_time":"2025-10-06T00:24:07.785465Z","start_time":"2025-10-06T00:24:07.569812Z"},"id":"5604135d","outputId":"c5f8b885-79d2-4aba-87be-aee87ea5819b"},"source":["\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","import pandas as pd\n","\n","docs = [\n","    \"кошки любят молоко\",\n","    \"собаки тоже любят молоко\",\n","    \"кошки не любят собак\"\n","]\n","\n","# --- BoW ---\n","bow = CountVectorizer()\n","X_bow = bow.fit_transform(docs)\n","bow_df = pd.DataFrame(X_bow.toarray(), columns=bow.get_feature_names_out())\n","print(\"Bag of Words (BoW):\")\n","display(bow_df)\n","\n","# --- TF-IDF ---\n","tfidf = TfidfVectorizer()\n","X_tfidf = tfidf.fit_transform(docs)\n","tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n","print(\"TF-IDF:\")\n","display(tfidf_df.round(3))\n"],"outputs":[{"name":"stdout","output_type":"stream","text":["Bag of Words (BoW):\n"]},{"data":{"text/plain":["   кошки  любят  молоко  не  собак  собаки  тоже\n","0      1      1       1   0      0       0     0\n","1      0      1       1   0      0       1     1\n","2      1      1       0   1      1       0     0"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>кошки</th>\n","      <th>любят</th>\n","      <th>молоко</th>\n","      <th>не</th>\n","      <th>собак</th>\n","      <th>собаки</th>\n","      <th>тоже</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["TF-IDF:\n"]},{"data":{"text/plain":["   кошки  любят  молоко     не  собак  собаки   тоже\n","0  0.620  0.481   0.620  0.000  0.000   0.000  0.000\n","1  0.000  0.345   0.445  0.000  0.000   0.584  0.584\n","2  0.445  0.345   0.000  0.584  0.584   0.000  0.000"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>кошки</th>\n","      <th>любят</th>\n","      <th>молоко</th>\n","      <th>не</th>\n","      <th>собак</th>\n","      <th>собаки</th>\n","      <th>тоже</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.620</td>\n","      <td>0.481</td>\n","      <td>0.620</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000</td>\n","      <td>0.345</td>\n","      <td>0.445</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.584</td>\n","      <td>0.584</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.445</td>\n","      <td>0.345</td>\n","      <td>0.000</td>\n","      <td>0.584</td>\n","      <td>0.584</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"output_type":"display_data"}],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","pygments_lexer":"ipython3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}